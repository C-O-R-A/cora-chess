{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde99f41",
   "metadata": {},
   "source": [
    "# Chess Move Prediction Pipeline\n",
    "\n",
    "This notebook loads player game data, constructs a PyTorch dataset for chess\n",
    "positions, builds a convolutional neural network to predict moves, and trains\n",
    "the model using variable-length legal move lists.\n",
    "\n",
    "Sections:\n",
    "\n",
    "1. Load and merge move, board, and game metadata  \n",
    "2. Build a custom PyTorch dataset  \n",
    "3. Implement residual CNN modules  \n",
    "4. Build the main neural network  \n",
    "5. Train the model with variable-length legal move lists  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda08ba3",
   "metadata": {},
   "source": [
    "## Load Player Data\n",
    "\n",
    "`Load_player_data()` loads and merges all the information required to train the\n",
    "model:\n",
    "\n",
    "- Reads move CSV and board CSV  \n",
    "- Merges them into corresponding positions  \n",
    "- Handles starting positions for first white moves  \n",
    "- Adds ECO codes and game metadata  \n",
    "- Fills missing FENs and material counts  \n",
    "- Saves a combined CSV for debugging  \n",
    "- Returns the unified DataFrame and ECO mapping dictionary  \n",
    "\n",
    "This function prepares the cleaned data that drives the dataset class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_player_data(player_name, move_csv_path, game_csv_path, eco_csv_path):\n",
    "    '''\n",
    "    move data should contain move, game_id, move_no_pair, player, color\n",
    "    board data should contain the rest\n",
    "    '''\n",
    "\n",
    "    # Load move and board data from the same CSV (assuming this is correct)\n",
    "    move_data = pd.read_csv(move_csv_path, usecols=['game_id', 'move_no_pair', 'color', 'move', 'player'])\n",
    "    board_data = pd.read_csv(move_csv_path, usecols=['game_id', 'move_no_pair', 'player', 'color', 'fen', 'white_count', 'black_count'])\n",
    "\n",
    "    # Filter moves made by the target player\n",
    "    move_data = move_data[move_data['player'].str.contains(player_name, na=False)]\n",
    "\n",
    "    # Filter board positions before target player moves\n",
    "    board_data = board_data[~board_data['player'].str.contains(player_name, na=False)]\n",
    "\n",
    "    # Calculate corresponding board move_no_pair for each move:\n",
    "    move_data_adj = move_data.copy()\n",
    "    move_data_adj['board_move_no_pair'] = move_data_adj.apply(\n",
    "        lambda row: row['move_no_pair'] - 1 if row['color'].lower() == 'white' else row['move_no_pair'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Identify first white moves (no prior board)\n",
    "    first_white_moves = move_data_adj[move_data_adj['board_move_no_pair'] == 0]\n",
    "\n",
    "    # Default starting board state\n",
    "    starting_fen = 'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR'\n",
    "    starting_white_count = 16\n",
    "    starting_black_count = 16\n",
    "\n",
    "    if not first_white_moves.empty:\n",
    "        starting_board_data = first_white_moves[['game_id']].copy()\n",
    "        starting_board_data['move_no_pair'] = 0  # for matching\n",
    "        starting_board_data['fen'] = starting_fen\n",
    "        starting_board_data['white_count'] = starting_white_count\n",
    "        starting_board_data['black_count'] = starting_black_count\n",
    "        starting_board_data['player'] = 'default'\n",
    "        starting_board_data['color'] = 'Black'  # set color so this matches board_data columns\n",
    "\n",
    "        # Append default starting boards to board_data\n",
    "        board_data = pd.concat([board_data, starting_board_data], ignore_index=True)\n",
    "\n",
    "    # Make sure no missing columns before merge and drop player from board_data\n",
    "    board_data = board_data.drop(columns=['player'])\n",
    "\n",
    "    # Merge moves with boards on game_id and move number\n",
    "    play_data = pd.merge(\n",
    "        move_data_adj,\n",
    "        board_data,\n",
    "        left_on=['game_id', 'board_move_no_pair'],\n",
    "        right_on=['game_id', 'move_no_pair'],\n",
    "        how='left',\n",
    "        suffixes=('_move', '_board')\n",
    "    )\n",
    "\n",
    "    # Load game metadata with game_id column for merging\n",
    "    game_data = pd.read_csv(game_csv_path)\n",
    "    # Assumption: game_data contains 'game_id', 'date_played', 'eco'\n",
    "    if 'game_id' not in game_data.columns:\n",
    "        raise ValueError(\"game_csv_path file must contain 'game_id' column\")\n",
    "\n",
    "    # Load ECO codes CSV and create mapping\n",
    "    eco_df = pd.read_csv(eco_csv_path)\n",
    "    eco_df = eco_df.sort_values(by='eco').reset_index(drop=True)\n",
    "    eco_mapping = {eco: idx+1 for idx, eco in enumerate(eco_df['eco'].values)}\n",
    "\n",
    "    # Merge game info to play_data on game_id\n",
    "    combined_data = pd.merge(game_data, play_data, on='game_id', how='left')\n",
    "\n",
    "    # Fill any missing values for important columns\n",
    "    combined_data['fen'] = combined_data['fen'].fillna(starting_fen)\n",
    "    combined_data['white_count'] = combined_data['white_count'].fillna(starting_white_count).astype(int)\n",
    "    combined_data['black_count'] = combined_data['black_count'].fillna(starting_black_count).astype(int)\n",
    "    combined_data['color_move'] = combined_data['color_move'].fillna('Unknown')\n",
    "\n",
    "    combined_data['move'] = combined_data['move'].fillna('')  # or whatever default\n",
    "\n",
    "    # Save combined data\n",
    "    combined_data.to_csv(\"loaded_magnus_move_data.csv\", index=False)\n",
    "\n",
    "    # For debugging, print fen types\n",
    "    print(play_data['fen'].apply(type).value_counts())\n",
    "\n",
    "    return combined_data, eco_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4e76e",
   "metadata": {},
   "source": [
    "## ChessDataset (PyTorch)\n",
    "\n",
    "`ChessDataset` converts each row of the merged DataFrame into training-ready\n",
    "tensors:\n",
    "\n",
    "- Converts FEN → 6×8×8 tensor of piece planes  \n",
    "- Computes legal moves using `python-chess`  \n",
    "- Computes the target move index within legal moves  \n",
    "- Constructs auxiliary numeric features  \n",
    "- Returns a dictionary containing:\n",
    "\n",
    "  - `\"board\"` : 6×8×8 tensor  \n",
    "  - `\"extra\"` : auxiliary features  \n",
    "  - `\"legal_moves\"` : `[N_i, 2]` tensor of legal moves  \n",
    "  - `\"target_index\"` : index of the correct move  \n",
    "\n",
    "This dataset supports variable-length legal move lists by returning a Python\n",
    "list of samples instead of stacking them automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        data: tuple (DataFrame, eco_to_idx) or just DataFrame\n",
    "        \"\"\"\n",
    "        self.data = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        fen = row['fen']\n",
    "        board = chess.Board(fen)\n",
    "\n",
    "        # Set correct turn\n",
    "        board.turn = chess.WHITE if row['color_move'] == 'White' else chess.BLACK\n",
    "\n",
    "        # Legal moves\n",
    "        legal_moves = [(m.from_square, m.to_square) for m in board.legal_moves]\n",
    "        legal_moves_tensor = torch.tensor(legal_moves, dtype=torch.float32)  # [N,2]\n",
    "\n",
    "        # Target index in legal moves\n",
    "        target_move = (chess.Move.from_uci(row['move']).from_square,\n",
    "                       chess.Move.from_uci(row['move']).to_square)\n",
    "        target_index = legal_moves.index(target_move)\n",
    "        target_index = torch.tensor(target_index, dtype=torch.long)\n",
    "\n",
    "        # Board tensor\n",
    "        board_tensor = self.convert_board_to_tensor(fen)  # [6,8,8]\n",
    "\n",
    "        # Extra features\n",
    "        extra_features = torch.tensor([\n",
    "            self.process_date_played(row['date_played']),\n",
    "            int(row['move_no_pair_move']),\n",
    "            0 if row['color_move'] == 'White' else 1\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            \"board\": board_tensor,\n",
    "            \"extra\": extra_features,\n",
    "            \"legal_moves\": legal_moves_tensor,\n",
    "            \"target_index\": target_index\n",
    "        }\n",
    "    \n",
    "    def convert_board_to_tensor(self,board_fen):\n",
    "        pieces = ['p', 'r', 'n', 'b', 'q', 'k']\n",
    "        board = chess.Board(board_fen)\n",
    "        board_str = str(board).replace(' ','').replace('\\n','')\n",
    "        layers = []\n",
    "        for piece in pieces:\n",
    "            arr = np.zeros((8,8), dtype=np.float32)\n",
    "            for i,char in enumerate(board_str):\n",
    "                row, col = divmod(i, 8)\n",
    "                if char == piece:\n",
    "                    arr[row, col] = -1\n",
    "                elif char == piece.upper():\n",
    "                    arr[row, col] = 1\n",
    "            layers.append(arr)\n",
    "\n",
    "        return torch.tensor(np.stack(layers), dtype=torch.float32)\n",
    "    \n",
    "    def process_date_played(self, date_played):\n",
    "        date_played = date_played.replace(\"??\", \"01\")\n",
    "        dt = datetime.strptime(date_played, \"%Y.%m.%d\")\n",
    "        epoch = datetime(1970,1,1)\n",
    "        delta_days = (dt - epoch).days\n",
    "        return delta_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d05d21",
   "metadata": {},
   "source": [
    "## NeuralNet (Convolutional Policy Network)\n",
    "\n",
    "The neural network processes each board position as follows:\n",
    "\n",
    "1. Initial convolution over the 6×8×8 board planes  \n",
    "2. Stack of residual blocks  \n",
    "3. Flatten into a feature vector  \n",
    "4. Combine with auxiliary features  \n",
    "5. (Later) score legal moves  \n",
    "\n",
    "This network does *not* assume a fixed number of moves, so it does not output a\n",
    "fixed-size vector. Instead, during training, we pass the legal moves separately\n",
    "and compute per-move scores inside the training loop or inside a higher-level\n",
    "selector model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6975d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class module(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(module, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(hidden_size, hidden_size, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_size, hidden_size, 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_size)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_size)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        \n",
    "        self.layers = nn.Sequential(self.conv1, self.bn1, self.activation1, self.conv2, self.bn2)\n",
    "\n",
    "        self.activation2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_input = torch.clone(x)\n",
    "        x = self.layers(x)\n",
    "        x = x + x_input\n",
    "        x = self.activation2(x)\n",
    "        return x  \n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    '''\n",
    "    A convolutional neural network for predicting chess moves from a board tensor\n",
    "    and auxiliary (non-spatial) features.\n",
    "\n",
    "    The network processes a 6×8×8 input tensor representing piece placements across\n",
    "    six channels (e.g., piece-type × color planes). It applies an initial convolution,\n",
    "    a stack of residual blocks, then flattens the result and combines it with\n",
    "    additional non-board features. \n",
    "    '''\n",
    "\n",
    "    def __init__(self, hidden_layers=4, hidden_size=200, extra_feature_dim=3):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        Initialize the neural network.\n",
    "\n",
    "        Args:\n",
    "            hidden_layers (int):\n",
    "                Number of residual blocks applied after the initial convolution.\n",
    "            hidden_size (int):\n",
    "                Number of feature channels in the convolutional and residual layers.\n",
    "            extra_feature_dim (int):\n",
    "                Dimension of the auxiliary non-board input feature vector\n",
    "                (e.g., side-to-move, castling rights, move counters).\n",
    "\n",
    "        Components created:\n",
    "            • input_conv: first 3×3 convolution mapping 6 channels → hidden_size  \n",
    "            • bn_input: batch normalization for the input convolution  \n",
    "            • activation: shared ReLU activation  \n",
    "            • res_blocks: a Sequential container of `hidden_layers` residual blocks  \n",
    "            • flatten: flattens convolutional output to a vector  \n",
    "            • fc_extra: linear layer that embeds auxiliary features to 64 units  \n",
    "\n",
    "        '''\n",
    "        self.input_conv = nn.Conv2d(6, hidden_size, kernel_size=3, padding=1)\n",
    "        self.bn_input = nn.BatchNorm2d(hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[module(hidden_size) for _ in range(hidden_layers)]\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_extra = nn.Linear(extra_feature_dim, 64)\n",
    "\n",
    "    def forward(self, board_tensor, extra_features, legal_moves):\n",
    "        '''\n",
    "        Run a forward pass of the network.\n",
    "\n",
    "        Args:\n",
    "            board_tensor (Tensor):\n",
    "                A float tensor of shape (batch_size, 6, 8, 8) representing the chess\n",
    "                board. Each of the 6 channels typically encodes a piece type and color\n",
    "                (e.g., white pawns, white pieces, black pawns, …).\n",
    "\n",
    "            extra_features (Tensor):\n",
    "                A tensor of shape (batch_size, extra_feature_dim) containing\n",
    "                side-information not encoded spatially (e.g., castling rights,\n",
    "                fifty-move counter, who's to move).\n",
    "                \n",
    "            legal_moves (Tensor): \n",
    "                A tensor of legal moves with square index coordinates\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        x = self.input_conv(board_tensor)\n",
    "        x = self.bn_input(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x_extra = self.fc_extra(extra_features)\n",
    "        x_extra = self.activation(x_extra)\n",
    "\n",
    "        # concatenate extra features\n",
    "        x = torch.cat([x, x_extra], dim=1)\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d0cf8",
   "metadata": {},
   "source": [
    "## Training Loop (train_model2)\n",
    "\n",
    "The training loop:\n",
    "\n",
    "- Creates a dataset and DataLoader  \n",
    "- Uses a custom `collate_fn` to avoid stacking variable-length legal move lists  \n",
    "- Stacks board and extra feature tensors  \n",
    "- Leaves legal moves as a Python list (`[N_i,2]` per sample)  \n",
    "- Calls the model to get per-move probability distributions  \n",
    "- Applies negative log-likelihood loss using the target move index  \n",
    "- Updates the model with Adam optimizer  \n",
    "- Saves model weights after each epoch  \n",
    "\n",
    "This training approach supports variable-length move sets using loops rather\n",
    "than fixed-size tensors, simplifying the model design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ef4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(modelname, dataset, num_epochs=100, batch_size=32, lr=1e-3):\n",
    "    data_train = ChessDataset(dataset)\n",
    "    data_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
    "    model = NeuralNet()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in data_loader:\n",
    "            # batch is a list of dicts because legal_moves are variable-length\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Stack the tensors by batch size\n",
    "            board = torch.stack([item['board'] for item in batch]).to(device)\n",
    "            extra = torch.stack([item['extra'] for item in batch]).to(device)\n",
    "            legal_moves_list = [item['legal_moves'].to(device) for item in batch]\n",
    "            target_indices = [item['target_index'].to(device) for item in batch]\n",
    "\n",
    "            outputs = model(board, extra, legal_moves_list)  # list of [N_i] probabilities\n",
    "\n",
    "            # Compute negative log-likelihood loss\n",
    "            loss = 0.0\n",
    "            for probs, target_idx in zip(outputs, target_indices):\n",
    "                loss += -torch.log(probs[target_idx])\n",
    "            loss = loss / len(batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(data_loader):.4f}\")\n",
    "        torch.save(model.state_dict(), f'models/{modelname}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41d200",
   "metadata": {},
   "source": [
    "## Train on Magnus Carlsen's Games\n",
    "\n",
    "We load Magnus Carlsen's move history, merge it with game data and ECO codes,\n",
    "construct training samples, and train the network.\n",
    "\n",
    "This provides the full pipeline:\n",
    "\n",
    "Raw CSV data → Cleaned dataset → PyTorch network → Training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnus_data = Load_player_data('Carlsen', \n",
    "                 '/home/matth/Desktop/Colossus/Software/chess/chess/data/game_data/Carlsen, Magnus/Carlsen_moves.csv', \n",
    "                 '/home/matth/Desktop/Colossus/Software/chess/chess/data/game_data/Carlsen, Magnus/Carlsen_game_info.csv', \n",
    "                 '/home/matth/Desktop/Colossus/Software/chess/chess/data/game_data/Carlsen, Magnus/eco_codes.csv')\n",
    "\n",
    "train_model('magnus', magnus_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
